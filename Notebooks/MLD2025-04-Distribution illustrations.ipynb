{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table width=\"100%\">\n",
    "    <td align=\"left\">\n",
    "        <a target=\"_blank\", href=\"https://www.up.pt/fcup/en/\">\n",
    "            <img src=\"https://divulgacao.iastro.pt/wp-content/uploads/2023/03/FCUP_logo-print_blcktransp_600ppi.png\" width=\"90px\" height=\"90px\" style=\"padding-bottom:5px;\"/>\n",
    "        </a>\n",
    "    </td>\n",
    "    <td>\n",
    "        <a target=\"_blank\", href=\"https://www.iastro.pt/\">\n",
    "            <img src=\"https://divulgacao.iastro.pt/wp-content/uploads/2018/03/IA_logo_bitmap-rgbblack-1200px-388x259.png\" width=\"90px\" height=\"90px\" style=\"padding-bottom:5px;\"/>\n",
    "        </a>\n",
    "    </td>\n",
    "    <td align=\"center\">\n",
    "        <a target=\"_blank\" href=\"https://colab.research.google.com/github/jbrinchmann/MLD2025/blob/main/Notebooks/MLD2025-04-Distribution%20illustrations.ipynb\">\n",
    "           <img src=\"https://tinyurl.com/3mm2cyk6\"  width=\"90px\" height=\"90px\" style=\"padding-bottom:5px;\"/>Run in Google Colab\n",
    "        </a>\n",
    "    </td>\n",
    "<td align=\"center\"><a target=\"_blank\" href=\"https://github.com/jbrinchmann/MLD2025/blob/main/Notebooks/MLD2025-04-Distribution%20illustrations.ipynb\">\n",
    "<img src=\"https://tinyurl.com/25h5fw53\"  width=\"90px\" height=\"60px\" style=\"padding-bottom:0px;\"  />View Source on GitHub</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T22:34:07.700668Z",
     "start_time": "2019-03-09T22:34:07.695504Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"colorblind\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T22:34:20.154116Z",
     "start_time": "2019-03-09T22:34:20.151382Z"
    }
   },
   "outputs": [],
   "source": [
    "# I like bigger plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Comparing multiple distributions\n",
    "\n",
    "This simple notebook is created to compare ways to display distributions. Here in particular I want to show how to compare multiple distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T22:34:24.517302Z",
     "start_time": "2019-03-09T22:34:24.512512Z"
    }
   },
   "outputs": [],
   "source": [
    "centre1 = [1.0, 1.3, 2.8, 1.8, 4.5, 7.6]\n",
    "scale1 = [0.6, 0.3, 0.7, 1.5, 1.2, 0.7]\n",
    "centre2 = [None, None, 0.5, 3.2, None, 2.5]\n",
    "scale2 = [1.0, 1.0, 0.7, 0.6, 1.0, 0.9]\n",
    "norm = [1.0, 1.0, 0.8, 1.7, 1.0, 1.0]\n",
    "\n",
    "N_ref= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T22:34:24.524902Z",
     "start_time": "2019-03-09T22:34:24.519739Z"
    }
   },
   "outputs": [],
   "source": [
    "d = dict()\n",
    "\n",
    "# I also want to count the total number of data points\n",
    "n_total_data = 0\n",
    "for i in range(len(centre1)):\n",
    "    x_r1 = np.random.normal(centre1[i], scale1[i], size=N_ref)\n",
    "    if centre2[i] is None:\n",
    "        pass\n",
    "    else:\n",
    "        x_r2 = np.random.normal(centre2[i], scale2[i], size=int(N_ref*norm[i]))\n",
    "        x_r1 = np.append(x_r1, x_r2)\n",
    "        \n",
    "    d[i] = x_r1\n",
    "    n_total_data += len(x_r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T00:10:12.507733Z",
     "start_time": "2019-03-09T00:10:12.377683Z"
    }
   },
   "source": [
    "## Showing the data fully\n",
    "\n",
    "This plots points in vertical strips. There are various ways to do this. I will first use a simple approach using matplotlib and then show a more complex, but powerful way to convert the data into a form useful for Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T22:34:24.707197Z",
     "start_time": "2019-03-09T22:34:24.526475Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1)\n",
    "\n",
    "# I need to know the number of columns to show\n",
    "n_columns = len(d.keys())\n",
    "# Allow some jitter to show the data better.\n",
    "jitter = 0.2\n",
    "\n",
    "for i in range(n_columns):\n",
    "    y = d[i]\n",
    "    x = i+np.random.uniform(size=len(y))*jitter\n",
    "    ax.scatter(x, y, alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T00:18:49.209024Z",
     "start_time": "2019-03-09T00:18:43.969648Z"
    }
   },
   "source": [
    "To show this using `stripplot` in seaborn we need to massage the data a bit. We need now to have one vector with all data and another with the id of each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T22:34:24.712512Z",
     "start_time": "2019-03-09T22:34:24.709828Z"
    }
   },
   "outputs": [],
   "source": [
    "data_vector = np.zeros(n_total_data)\n",
    "label_vector = np.zeros(n_total_data, int) # This could instead be a string array for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T22:34:24.719177Z",
     "start_time": "2019-03-09T22:34:24.715615Z"
    }
   },
   "outputs": [],
   "source": [
    "i_start = 0\n",
    "for i in range(n_columns):\n",
    "    y = d[i]\n",
    "    i_end = i_start + len(y)\n",
    "    data_vector[i_start:i_end] = y\n",
    "    label_vector[i_start:i_end] = i\n",
    "    i_start = i_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T22:34:24.722905Z",
     "start_time": "2019-03-09T22:34:24.720725Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = {'y': data_vector, 'x': label_vector}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T22:34:25.021319Z",
     "start_time": "2019-03-09T22:34:24.724126Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.stripplot(x='x', y='y', data=ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silly histograms\n",
    "\n",
    "Next, try to compare these by overplotting histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T22:34:25.346919Z",
     "start_time": "2019-03-09T22:34:25.023327Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(d.keys())):\n",
    "    plt.hist(d[i], label=\"Dist {0}\".format(i), alpha=0.5)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layered histograms\n",
    "\n",
    "We could imagine making multiple histograms that are one above the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T22:34:25.354819Z",
     "start_time": "2019-03-09T22:34:25.348547Z"
    }
   },
   "outputs": [],
   "source": [
    "def plothist(x, bins='auto', yoffset=0, color=None, norm=False, peak=None,\n",
    "             fill=False, ax=None, **kwargs):\n",
    "    \"\"\"Convenience function for manually plotting a histogram\n",
    "    \n",
    "    This allows for a flexible baselevel\n",
    "    \"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    yhist, xbins = np.histogram(x, bins=bins, density=norm)\n",
    "    if peak is not None:\n",
    "        yhist = peak*yhist/np.max(yhist)\n",
    "\n",
    "    # But to get the edges of the histogram in the plot,\n",
    "    # we need to pad these a bit.\n",
    "    xhist = np.hstack([xbins[0], xbins, xbins[-1]])\n",
    "    yhist = np.hstack([0, yhist[0], yhist, 0])\n",
    "    \n",
    "    try:\n",
    "        col = kwargs['c']\n",
    "    except:\n",
    "        col = None\n",
    "    \n",
    "    # Finally, to make a histogram plot we use step and fill_between\n",
    "    plt.step(xhist, yhist+yoffset, where='pre', **kwargs)\n",
    "    if fill:\n",
    "        plt.fill_between(xhist, yhist+yoffset, yoffset, step='pre', color=col)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T22:34:25.470965Z",
     "start_time": "2019-03-09T22:34:25.356733Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "y_start = 0\n",
    "dy = 1.5\n",
    "for i in range(n_columns):\n",
    "    plothist(d[i], yoffset=y_start+dy*i, fill=False, ax=ax, peak=1, bins=20)\n",
    "    \n",
    "ax.set_ylabel('Distribution number')\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is not bad and might often be a good option but it does not summarise things very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better options - error bars and box plots\n",
    "\n",
    "We can summarise things in simple ways - that gives us error bars, and the next step is box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T22:34:25.623041Z",
     "start_time": "2019-03-09T22:34:25.472697Z"
    }
   },
   "outputs": [],
   "source": [
    "stdevs = np.zeros(n_columns)\n",
    "means = np.zeros_like(stdevs)\n",
    "for i in range(n_columns):\n",
    "    stdevs[i] = np.std(d[i])\n",
    "    means[i] = np.mean(d[i])\n",
    "\n",
    "xplot = np.arange(n_columns)\n",
    "plt.errorbar(xplot, means, stdevs, fmt='o', marker='o', capsize=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that throws away a lot of information and makes it seem as if the errors are symmetric. We can of course improve on this, but let us instead move to box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T22:34:25.627638Z",
     "start_time": "2019-03-09T22:34:25.624830Z"
    }
   },
   "outputs": [],
   "source": [
    "l = [d[i] for i in range(n_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T22:34:25.821956Z",
     "start_time": "2019-03-09T22:34:25.629275Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T22:58:13.990053Z",
     "start_time": "2019-03-09T22:58:13.784135Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.violinplot(data=l, density_norm='width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out \n",
    "\n",
    "A set of 13 datasets. The command to download the file in Colab is below - if you are running off your own machine, just copy or link the file into the directory with the notebook.\n",
    "\n",
    "Calculate summary statistics (mean, standard deviation, correlation coefficient, maybe a linear fit) for each dataset - what do you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --quiet -O several_datasets.tsv https://github.com/jbrinchmann/MLD2025/blob/main/Datafiles/several_datasets.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Astropy's table package might be a good way to read it in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "t = Table().read(\"several_datasets.tsv\", format=\"ascii.fast_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
